<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <title>Xuri Ge's Homepage (葛旭日的个人主页)</title>
    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900"
      rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i"
      rel="stylesheet">
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href="vendor/devicons/css/devicons.min.css" rel="stylesheet">
    <link href="vendor/simple-line-icons/css/simple-line-icons.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
  
    <!-- Custom styles for this template -->
    <link href="css/resume.min.css" rel="stylesheet">
    <link href="css/index.css" rel="stylesheet">
</head>

<body id="page-top">

  <!-- Copyright ? 2008. Spidersoft Ltd -->
  <style>
  </style>
  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none"></span>
      <span class="d-none d-lg-block">
        <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="./img/gxr.jpg" alt="">
      </span>
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#about">About Me</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#publications">Publications</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#activities">Activities</a>
        </li>          
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#working-experiences">Working Experiences</a>
        </li>          
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#awards">Awards</a>
        </li>
      </ul>
    </div>
  </nav>

  <div class="container-fluid p-0">
    <section class="resume-section p-3 p-lg-5 d-flex d-column" id="about">
      <div class="my-auto">
        <h2 class="mb-0">Xuri Ge
          <span class="text-primary">(葛旭日)<a href="img/Xuri_PHD_Resume_noMM.pdf" target="_blank">[CV]</a></span>
        </h2>
        <div class="mb-5"> Best way to reach me &#8594
            Email: xurigexmu@gmail.com 
        </div>
        <p class="mb-5">I am currently a 4th-year Ph.D student at <a href="http://www.dcs.gla.ac.uk/">School of Computing Science</a>, <a href="http://www.gla.ac.uk">University of Glasgow</a>, Scotland, UK and a member of the <a href="https://gair-lab.github.io/">GAIR-Lab </a> in <a href="https://www.gla.ac.uk/schools/computing/research/researchsections/ida-section/">Information, Data and Analysis (IDA) </a> group. 
          My principal supervisor is <a href="http://www.dcs.gla.ac.uk/~jj/" target="_blank">Prof. Joemon M Jose</a> and second supervisor is <a href="https://scholar.google.com/citations?hl=zh-CN&user=mbSbOegAAAAJ" target="_blank">Dr. Gerardo Aragon Camarasa</a>. 
		I received my master's degree from Xiamen University in 2020. My advisors are <a href="http://mac.xmu.edu.cn/rrji-en.html">Prof. Rongrong Ji</a> and Minghui Shi.  During my master, I worked in the Laboratory of <a href="https://mac.xmu.edu.cn/index.htm" target="_blank">MAC</a>, Artificial Intelligence Department, School of Informatics, Xiamen University, China. <br>
		More recently, my main research attention in computer vision, natural language processing and multimedia, mainly including cross-modal retrieval, facial action unit detection, image captioning, medical image analysis, etc.
            <li>
               <b>Multi-modal Representation Learning</b>
            </li>
            <li>
               <b>Computer Vision (CV) and Natural Language Processing (NLP)</b>
            </li>
            <li>
               <b>Multimedia</b>
            </li>
        </p>
        <ul class="list-inline list-social-icons mb-0">
          <li class="list-inline-item">
            <a href="https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=xuri+ge&btnG=" target="_blank">
              <i class="ai ai-google-scholar-square ai-3x"></i>
            </a>
          </li>
          <li class="list-inline-item">
            <a href="https://github.com/GAIR-Lab" target="_blank">
              <i class="fa fa-github-square fa-3x"></i>
            </a>
          </li> 
	  <li class="list-inline-item">
            <a href="https://www.linkedin.com/in/xurige/" target="_blank">
              <i class="fa fa-linkedin-square fa-3x"></i>
            </a>
          </li> 
	  <li class="list-inline-item">
            <a href="https://twitter.com/Solis_xurige" target="_blank">
              <i class="fa fa-twitter-square fa-3x"></i>
            </a>
          </li> 
        </ul>
        <br>
                <h3 id="latest-news">--Latest News--</h3>
            
            <ul>
		<li>
                    <a href="index.html">June 26, 2024</a>
                    <p> <b>One full paper is accepted by ICPR2024 !!</p></b>
                </li>
                <li>
                    <a href="index.html">Mar 26, 2024</a>
                    <p> <b>Two full papers are accepted by SIGIR2024 !!</p></b>
                </li>
                <li>
                    <a href="index.html">Mar 4, 2024</a>
                    <p> <b>We are organizing a <a href="https://3dmm-icme2024.github.io/">3DMM Workshop</a> at <a href="https://2024.ieeeicme.org/">ICME2024 (Niagra Falls, Canada)</a>. All submissions about 3D multimedia are welcome!</p></b>
                </li>
                <li>
                    <a href="index.html">Mar 13, 2024</a>
                    <p> <b>One paper is accepted by ICME2024!</p></b>
                </li>

                <li>
                    <a href="index.html">Mar 10, 2024</a>
                    <p> <b>Our paper is accepted by IP&M!</b></p></b>
                </li>

                <li>
                    <a href="index.html">Jan 24, 2024</a>
                    <p> <b>Our paper is accepted by TIST!</b></p></b>
                </li>

                <!-- More news items -->
            </ul>
	</li>
        </div>

    </section>
    
	
    <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="publications">
      <div>
        <h3 class="mb-5">Publications</h3>
        <ol>
	    <h4 id="published"> Published: </h4>
	     <!-- 文章序列14 -->	
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/IISAN.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                Junchen Fu, <b>Xuri Ge</b><sup>✉</sup>, Xin Xin, Alexandros Karatzoglou, Ioannis Arapakis, Jie Wang, Joemon M. Jose <br>
                <b>IISAN: Efficiently Adapting Multimodal Representation for Sequential Recommendation with Decoupled PEFT.</b> 
                  <a href="https://arxiv.org/abs/2404.02059" target="_blank">[pdf]</a> 
                  <a href="https://github.com/jjGenAILab/IISAN" target="_blank">[code]</a>
                  <br> the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2024. (Core Rank A*)
              </div>
            </div> 
	    <!-- 文章序列13 -->	
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/CFIR.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                Zijun Long, <b>Xuri Ge</b><sup>✉</sup>, Richard Mccreadie, Joemon M. Jose<br>
                <b>CFIR: Fast and Effective Long-Text To Image Retrieval for Large Corpora.</b> 
                  <a href="https://arxiv.org/abs/2402.15276" target="_blank">[pdf]</a> 
                  <a href="https://github.com/longkukuhi/CFIR" target="_blank">[code]</a>
                  <br> the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2024. (Core Rank A*)
              </div>
            </div> 
            <!-- 文章序列12 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/SHNet.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                <b>Xuri Ge</b>, Songpei Xu, Fuhai Chen<sup>✉</sup>, Jie Wang, Guoxin Wang, Shan An, Joemon M. Jose<sup>✉</sup> <br>
                <b>3SHNet: Boosting Image-Sentence Retrieval via Visual Semantic-Spatial Self-Highlighting.</b> <b>[J]</b>
                  <a href="https://www.sciencedirect.com/science/article/pii/S0306457324000761" target="_blank">[pdf]</a> 
                  <a href="https://github.com/XuriGe1995/3SHNet" target="_blank">[code]</a>
                  <br>Information Processing and Management (IP&M), 2024. (IF=8.6, JCR Q1)
              </div>
            </div> 
	<!-- 文章序列5 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/ICPR24.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                Tong Shi, <b>Xuri Ge</b>, Joemon M Jose, Nicolas Pugeault, Paul Henderson<br>
                <b>Detail-Enhanced Intra-and Inter-modal Interaction for Audio-Visual Emotion Recognition.</b>
                  <a href="https://arxiv.org/pdf/2405.16701" target="_blank">[Arxiv]</a>
                <br>27th International Conference on Pattern Recognition (ICPR), 2024.
              </div>
            </div>
            <!-- 文章序列11 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/HpEIS.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                Songpei Xu, <b>Xuri Ge</b><sup>✉</sup>, Chaitanya Kaul, Roderick Murray-Smith.<br>
                <b>HpEIS: Learning Hand Pose Embeddings for Multimedia Interactive Systems.</b>
                  <a href="xxx" target="_blank">[pdf coming]</a>
                  <br>IEEE Conference on Multimedia Expo (<b>ICME</b>), 2024. <a href="http://portal.core.edu.au/conf-ranks/" target="_blank">[CORE Rank A]</a>
              </div>
            </div> 
            <!-- 文章序列10 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/MGRRNet.jpg"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                <b>Xuri Ge</b><sup>✉</sup>, Joemon M. Jose, Songpei Xu, Xiao Liu, Hu Han <br>
                <b>MGRR-Net: Multi-level Graph Relational Reasoning Network for Facial Action Units Detection.</b> <b>[J]</b>
                  <a href="https://arxiv.org/pdf/2204.01349.pdf" target="_blank">[pdf]</a>
                  <br>ACM Transactions on Intelligent Systems and Technology (TIST), 2024. (IF=5.0, JCR Q2)
              </div>
            </div> 
	    <!-- 文章序列9 -->  
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/ECIR_LegalRec.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                Jie Wang, Bansal Kanha, Arapakis Ioannis, <b>Xuri Ge</b>, Joemon M. Jose <br>
                <b>Empowering Legal Citation Recommendation via Efficient Struction-Tuning of Pre-trained Language Models.</b> 
                  <a href="https://eprints.gla.ac.uk/312852/" target="_blank">[pdf]</a>
                  <br>The 46th European Conference on Information Retrieval (<b>ECIR</b>), 2024. <a href="http://portal.core.edu.au/conf-ranks/" target="_blank">[CORE Rank A]</a>
              </div>
            </div> 
	    <!-- 文章序列8 -->	
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/ALGRNet.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
		<b>Xuri Ge</b><sup>✉</sup>, Joemon M. Jose, Pengcheng Wang, Arunachalam Iyer, Xiao Liu, Hu Han <br>
                <b>ALGRNet: Multi-Relational Adaptive Facial Action Unit Modelling for Face Representation and Relevant Recognitions.</b> <b>[J]</b>
                  <a href="https://ieeexplore.ieee.org/abstract/document/10225375" target="_blank">[pdf]</a>
                  <br>IEEE Transactions on Biometrics, Behavior, and Identity Science (<b>TBIOM</b>), 2023.
              </div>
            </div> 
            <!-- 文章序列7 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/WACV23.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                <b>Xuri Ge</b>, Fuhai Chen<sup>✉</sup>, Songpe Xu, Fuxiang Tao, Joemon M. Jose.<br>
                <b>Cross-modal Semantic Enhanced Interaction for Image-Sentence Retrieval.</b>
                  <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Ge_Cross-Modal_Semantic_Enhanced_Interaction_for_Image-Sentence_Retrieval_WACV_2023_paper.pdf" target="_blank">[pdf]</a>
                  <br>Winter Conference on Applications of Computer Vision (<b>WACV2023</b>), 2023.<a href="http://portal.core.edu.au/conf-ranks/" target="_blank">[CORE Rank A]</a>
              </div>
            </div> 
            <!-- 文章序列6 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/ICASSP23_02.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
		Fuxiang Tao, <b>Xuri Ge<sup>✉</sup></b>, Wei Ma, Anna Esposito, Alessandro Vinciarelli.<br>
                <b>Multi-Local Attention for Speech-based Depression Detection.</b>
                  <a href="https://ieeexplore.ieee.org/abstract/document/10095757" target="_blank">[pdf]</a>
                  <br>IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), 2023.<a href="https://www.ccf.org.cn/Academic_Evaluation/CGAndMT/" target="_blank">[CCF B]</a>
              </div>
            </div> 
            <!-- 文章序列5 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/ICASSP23_01.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                Songpei Xu, Chaitanya Kaul, <b>Xuri Ge</b>, Roderick Murray-Smith.<br> 
                <b>Continuous Interaction with a Smart Speaker via Low-dimensional Embeddings of Dynamic Hand Pose.</b>
                  <a href="https://ieeexplore.ieee.org/abstract/document/10096097" target="_blank">[pdf]</a>
                  <br>IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), 2023.<a href="https://www.ccf.org.cn/Academic_Evaluation/CGAndMT/" target="_blank">[CCF B]</a>
              </div>
            </div> 
            <!-- 文章序列4 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/MM21.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                <b>Xuri Ge<sup>✉</sup></b>, Fuhai Chen, Joemon M. Jose, Zhilong Ji, Zhongqin Wu, Xiao Liu.<br>
                <b>Structured Multi-modal Feature Embedding and Alignment for Image-Sentence Retrieval.</b>
                  <a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475634" target="_blank">[pdf]</a>
                  <br>ACM International Conference on Multimedia (<b>ACM MM</b>), 2021. <a href="http://portal.core.edu.au/conf-ranks/" target="_blank">[CORE Rank A*]</a>
              </div>
            </div>
            <!-- 文章序列3 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/FG2021.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                <b>Xuri Ge<sup>*✉</sup></b>, Pengcheng Wang<sup>*</sup>, Hu Han, Joemon M. Jose, Zhonglong Ji, Zhongqin Wu, Xiao Liu.<br>
                <b>Local Global Relational Network for Facial Action Units Recognition. (Long-paper, Full Oral Report)</b>
                  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9666961" target="_blank">[pdf]</a>
                  <br>IEEE International Conference on Automatic Face and Gesture Recognition (<b>FG</b>), 2021. <a href="http://portal.core.edu.au/conf-ranks/" target="_blank">[CORE Rank B]</a> <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" target="_blank">[TH-CPL Rank B]</a>
              </div>
            </div> 
            <!-- 文章序列2 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/VSSI-cap.jpg"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                Fuhai Chen, Rongrong Ji<sup>✉</sup>, Jiayi Ji, Xiaoshuai Sun, Baochang Zhang, <b>Xuri Ge</b>, Yongjian Wu, Feiyue Huang, Yan Wang.<br>
                <b>Variational Structured Semantic Inference for Diverse Image Captioning.</b> 
                  <a href="https://papers.nips.cc/paper/2019/file/9c3b1830513cc3b8fc4b76635d32e692-Paper.pdf" target="_blank">[pdf]</a>
                  <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:tH_IWjFIswMJ:scholar.google.com/&output=citation&scisdr=CgXTZw3gEPT2urJuOtQ:AAGBfm0AAAAAYTNoItTtRS8fbeNroTiFGHUOs-2i0HVF&scisig=AAGBfm0AAAAAYTNoImVQG9jvMVxn3NX3k1LbprxIJtoC&scisf=4&ct=citation&cd=-1&hl=zh-CN&scfhb=1" target="_blank">[BibTex]</a>
                  <br>The 33th Conference on Neural Information Processing Systems (<b>NeurIPS</b>). 2019. <a href="http://portal.core.edu.au/conf-ranks/" target="_blank">[CORE Rank A*]</a>
              </div>
            </div>
             <!-- 文章序列1 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/CIC.jpg"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                <b>Xuri Ge </b>, Fuhai Chen, Chen Shen, Rongrong Ji<sup>✉</sup><br>
                <b>Colloquial Image Captioning. (Oral Report)</b> 
                  <a href="https://ieeexplore.ieee.org/abstract/document/8785034" target="_blank">[pdf]</a>
                  <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:Ar-S88ImqegJ:scholar.google.com/&output=citation&scisdr=CgXTZw3gEPT2urJuXWM:AAGBfm0AAAAAYTNoRWMNxXTnIGpDg9iilQ81BRwHdJk7&scisig=AAGBfm0AAAAAYTNoRShMCF34OPULB3MQ1aOIe7VdXlzQ&scisf=4&ct=citation&cd=-1&hl=zh-CN&scfhb=1" target="_blank">[BibTex]</a>
		  <br> IEEE International Conference on Multimedia and Expo (<b>ICME</b>), 2019. <a href="http://portal.core.edu.au/conf-ranks/" target="_blank">[CORE Rank A]</a>
              </div>
            </div>
	    <br><!-- hline-->
          <div class="resume-item  align-self-center">
	    <h4 id="Pre-print"> Pre-print: </h4>
	    <!-- 文章序列5 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/Coming.jpg"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                <b>Xuri Ge</b>, Fuhai Chen, Songpei Xu, Fuxiang Tao, Jie Wang and Joemon M. Jose</sup><br>
                <b>Hire: Hybrid-modal Interaction with Multiple Relational Enhancements for Image-Text Matching.</b>
                  <a href="https://arxiv.org/abs/2406.18579" target="_blank">[Arxiv]</a>
                <br>Under review, 2024.
              </div>
            </div>
            <!-- 文章序列4 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/REF.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                Fuhai Chen#, <b>Xuri Ge#</b>, Xiaoshuai Sun, Yue Gao, Jianzhuang Liu, Fufeng Chen<sup>✉</sup>, Wenjie Li<sup>✉</sup><br>
                <b>Differentiated Relevances Embedding for Group-based Referring Expression Comprehension.</b>
                  <a href="https://arxiv.org/pdf/2203.06382.pdf" target="_blank">[Arxiv]</a>
                <br>Under review, 2023.
              </div>
            </div>
            <!-- 文章序列3 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/Depress.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                Fuxiang Tao, Wei Ma, <b>Xuri Ge</b><sup>✉</sup>, Anna Esposito, Alessandro Vinciarelli <br>
                <b>The Relationship Between Speech Features Changes When You Get Depressed: Feature Correlations for Improving Speed and Performance of Depression Detection.</b>
                  <a href="https://arxiv.org/pdf/2307.02892.pdf" target="_blank">[Arxiv]</a>
                  <br>Under review, 2023.
              </div>
            </div>
            <!-- 文章序列2 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/Auto-Gen.png"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                Fuhai Chen, Rongrong Ji<sup>✉</sup>, Chengpeng Dai, <b>Xuri Ge</b>, Shengchuang Zhang, Xiaojing Ma, Yue Gao.<br>
                <b>Factored Attention and Embedding for Unstructured-view Topic-related Ultrasound Report Generation.</b>
                  <a href="https://arxiv.org/pdf/2203.06458.pdf" target="_blank">[Arxiv]</a>
              </div>
            </div>
            <!-- 文章序列1 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/Coming.jpg"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                <b>Xuri Ge</b><sup>✉</sup>,Xiaoshuai Sun, Zhilong Ji, Pengcheng Wang, Xiao Liu, Zhongqin Wu<br>
                <b>The DenseCap-Guided Attention Network For Image-Text Matching.</b>
                  <a href="#" target="_blank">[pdf coming]</a>
                  <br>Under review. 
              </div>
            </div>
	    <br>
	    <!-- Patent -->
            <h4 id="patent"> Patent: </h4>
            <!-- Patent 2 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/patent.jpg"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                <b>Xuri Ge</b><sup>✉</sup>, Zhilong Ji, Xiao Liu<br>
                <b>检索方法、电子设备及计算机可读介质.</b>
                  <!-- <a href="#" target="_blank">[pdf coming]</a>-->
                  <br>Published: CN 112287159 A; Num: 202011506349.4
              </div>
            </div>
            <!-- Patent1 -->
            <div class="product-cell row align-items-center justify-content-center">
              <div class="col-lg-2 col-md-3 col-sm-12 col-xs-12">
                <li><img class="product-cell-img" src="img/patent.jpg"></li>
              </div>
              <div class="product-cell-text col-lg-10 col-md-9 col-sm-12 col-xs-12">
                <b>Xuri Ge</b><sup>✉</sup>, Zhilong Ji, Xiao Liu<br>
                <b>弹幕生成方法、装置、电子设备及计算机存储介质.</b>
                  <!--<a href="#" target="_blank">[pdf coming]</a>-->
                  <br>Published: CN 112016573 A; Num: 202011112941.6
              </div>
            </div>
          </div>
        </ol>
      </div>
    </section>
   
    <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="activities">
      <div class="my-auto">
        <h3 class="mb-5">Activities</h3>
          <ul>
              <li>Conference Reviewer: NeurIPS, ACM Multimedia, CIKM, BMVC, ICME, WACV, ECIR, FG, ICASSP, etc. </li>
              <li>Journal Reviewer:  International Journal of Computer Vision(IJCV), Transactions on Knowledge and Data Engineering(TKDE), Pattern Recognition(PR), The ACM Transactions on Information Systems (TOIS), Information Processing and Management(IP&M), Multimedia Systems, etc.</li>
	      <li>中国图象图形学学会(CSIG)会员. </li>
	      <p></p>
	      <li>Organizing committee of 3D Multimedia Analytics, Search and Generation (3DMM 2024) in ICME 2024 workshop (<a href="https://3dmm-icme2024.github.io/">Link</a>). </li>            
	      <li>Organizing committee of AutoGen-CDR19 challenge in MICCAI 2019 (<a href="http://mac.xmu.edu.cn/challenge/MICCAI2019-AutoGen-CDR19/index.html">Link</a>). </li>
              <li><a href="https://mac.xmu.edu.cn/info/1005/1150.htm"><b>1st</b> Prize</a> (team name: MAC-Group), award on Workshop of Automatic Generation of Cardiovascular Diagnostic Report, The 22th Medical Image Computing Computer Assisted Intervention (MICCAI 2019), 2019.</li>
	      <li><a href="https://rrc.cvc.uab.es/?ch=13&com=evaluation&task=3"><b>5th</b> Prize</a> (team name: SenseTime, method name: GraphLayout), award on ICDAR 2019 Robust Reading Challenge.</li>
          </ul>
      </div>
    </section> 
    
    <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="working-experiences">
      <div class="my-auto">
        <h3 class="mb-5">Working Experiences</h3>
	  <b> Msc Supervision, School of Computing Science, University of Glasgow </b>
          <ul>
	      <li>2023.07 - 2023.09, Kaiwen Zheng, <a href="xxxx">"Facial Micro-expression Recognition"</a>.    Now at University of Glasgow (PhD).</li>
	      <li>2023.07 - 2023.09, Qinglin Yang, <a href="xxxx">"Facial Paralysis Estimation"</a>.            Now at </li>  
	      <li>2023.07 - 2023.09, Shilong Meng, <a href="xxxx">"Facial Action Unit Detection"</a>.           Now at </li>
	      <li>2022.07 - 2022.09, Quang Trung Tran, <a href="xxxx">"Facial Micro-expression Recognition"</a>.Now at Scottish Water. </li>
          </ul>
          <b> Tutor, School of Computing Science, University of Glasgow, UK </b>
	  <ul>
              <li>Summer 2021, Teaching assistant of “Text as Data (Master)”, University of Glasgow.</li>
              <li>Summer 2021, Teaching assistant of “Web Science (M.)”, University of Glasgow.</li>
              <li>Spring 2022, Tutor of “Text as Data (M.)”, University of Glasgow.</li>
              <li>Spring 2022, Tutor of “Web Science (M.)”, University of Glasgow.</li>
              <li>Spring 2022, Tutor of “Information Visualisation (M.)”, University of Glasgow.</li>
              <li>Winter 2022, Tutor of “Machine Learning (M.)”, University of Glasgow.</li>
              <li>Winter 2022, Tutor of “Computer Vision (High-level)”, University of Glasgow.</li>
              <li>Spring 2023, Tutor of “Text as Data (M.)”, University of Glasgow.</li>
              <li>Spring 2023, Tutor of “Web Science (M.)”, University of Glasgow.</li>
              <li>Spring 2024, Tutor of “Web Science (M.)”, University of Glasgow.</li>
          </ul>
          <b>Company Researcher</b>
          <ul>
	      <li>2020.07 - 2021.04, Computer Vision Researcher, <a href="http://en.100tal.com/">TAL</a>.</li>
              <li>2019.03 - 2019.07, Research Intern, <a href="https://www.sensetime.com/en">SenseTime</a>.</li> 
          </ul>
          <b> Teaching assistant, School of Informatics, Xiamen University, China </b>
          <ul>
              <li>Spring 2018, Teaching assistant of “Introduction to Artificial Intelligence”, Xiamen University.</li>
          </ul>
      </div>
    </section> 
    
    

    <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="awards">
      <div class="my-auto">
        <h3 class="mb-5">Awards</h3>
        <ul class="fa-ul mb-0">
          <li><i class="fa-li fa fa-trophy text-warning"></i> China Scholarship Council (CSC) Scholarships, 2021.01-2025.01</li>
          <li><i class="fa-li fa fa-trophy text-warning"></i> Xiamen University Scholarship, 2017-2020</li>
        </ul>
      </div>
    </section>

  </div>
  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/resume.min.js"></script>

</body>
<style>
  

.product-cell {
    /* width: 130%; */
    /* height: 90px; */
    margin-top: 15px;
  }

  .product-cell-img {
    /* float: left; */
    width: 120px;
    height: 80px;
  }

  .product-cell-text {
    display: inline;
  }

  .product-cell-num {
    /* float: left; */
    /* height: 70px; */
    color: black;
    margin-left: 15px;
    /* line-height: 70px; */
    text-align: center;
  }
</style>
</html>
